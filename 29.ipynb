{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eUzqh9oKGqWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9f23e6-610a-42b7-e4fc-642550cafb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Seçilen yama boyutları: [7, 14]\n",
            "HDF5 dosyası bulunamadı, model eğitiliyor ve sonuçlar kaydediliyor...\n",
            "\n",
            "Iteration 1\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9920267921946482\n",
            "Ortalama Hata (Mean Absolute Error): 0.7424621854738934\n",
            "Kök Ortalama Kare Hata (RMSE): 1.1713507328730097\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 9.96427656756276\n",
            "\n",
            "Iteration 2\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "R-kare (R-squared) Değeri: 0.9913296030281885\n",
            "Ortalama Hata (Mean Absolute Error): 0.733027981489346\n",
            "Kök Ortalama Kare Hata (RMSE): 1.2214899637375998\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.022910775655427\n",
            "\n",
            "Iteration 3\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9906645990831273\n",
            "Ortalama Hata (Mean Absolute Error): 0.777206243004001\n",
            "Kök Ortalama Kare Hata (RMSE): 1.2674676949547687\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.876086041502385\n",
            "\n",
            "Iteration 4\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9921644736104411\n",
            "Ortalama Hata (Mean Absolute Error): 0.7209755521490623\n",
            "Kök Ortalama Kare Hata (RMSE): 1.1611932451404718\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 9.938204740432182\n",
            "\n",
            "Iteration 5\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "R-kare (R-squared) Değeri: 0.9924897665161004\n",
            "Ortalama Hata (Mean Absolute Error): 0.7103802943344237\n",
            "Kök Ortalama Kare Hata (RMSE): 1.1368342031489251\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.210015892761422\n",
            "\n",
            "Iteration 6\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "R-kare (R-squared) Değeri: 0.991885554024378\n",
            "Ortalama Hata (Mean Absolute Error): 0.7302309293088318\n",
            "Kök Ortalama Kare Hata (RMSE): 1.181679900501456\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.20654747730774\n",
            "\n",
            "Iteration 7\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "R-kare (R-squared) Değeri: 0.9927044437809176\n",
            "Ortalama Hata (Mean Absolute Error): 0.698366658635297\n",
            "Kök Ortalama Kare Hata (RMSE): 1.1204684086616123\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 9.707265121967174\n",
            "\n",
            "Iteration 8\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9910309586196662\n",
            "Ortalama Hata (Mean Absolute Error): 0.736874681543295\n",
            "Kök Ortalama Kare Hata (RMSE): 1.24234845962806\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.208845159072863\n",
            "\n",
            "Iteration 9\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9916837055512048\n",
            "Ortalama Hata (Mean Absolute Error): 0.7314173061821022\n",
            "Kök Ortalama Kare Hata (RMSE): 1.1962868829938487\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.156581609520634\n",
            "\n",
            "Iteration 10\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "R-kare (R-squared) Değeri: 0.9916749751947522\n",
            "Ortalama Hata (Mean Absolute Error): 0.7397053811275381\n",
            "Kök Ortalama Kare Hata (RMSE): 1.196914642833731\n",
            "Ortalama Mutlak Yüzde Hata (MAPE): 10.27136034907189\n",
            "Tüm grafikler başarıyla kaydedildi.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['AUTOGRAPH_VERBOSITY'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import h5py\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "start_time = time.time()\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "save_dir = '/content/drive/My Drive/colab_tez_icerikleri/Yeni'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# HDF5 dosya adı\n",
        "hdf5_filename = os.path.join(save_dir, 'model_ve_sonuclar_mevsimsel_momentumsuz.h5')\n",
        "\n",
        "data = pd.read_excel('/content/drive/My Drive//hepsi2.xlsx')\n",
        "\n",
        "# Tarih sütununu indeks olarak ayarlama ve sıralama\n",
        "data['Sipariş Tarihi'] = pd.to_datetime(data['Sipariş Tarihi'])\n",
        "data.set_index('Sipariş Tarihi', inplace=True)\n",
        "data.sort_index(inplace=True)\n",
        "\n",
        "# Günlük toplam satışları hesapla\n",
        "daily_sales = data['Net fiyat'].resample('D').sum()\n",
        "\n",
        "# Eğitim ve test verilerini ayırma\n",
        "train_start_date = '2022-01-01'\n",
        "train_end_date = '2023-05-31'\n",
        "test_start_date = '2023-05-31'\n",
        "test_end_date = '2023-10-31'\n",
        "\n",
        "train_data = data[train_start_date:train_end_date]\n",
        "test_data = data[test_start_date:test_end_date]\n",
        "\n",
        "# Veriyi Ölçeklendirme\n",
        "scaler = MinMaxScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "test_data_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Veri Frekansını Belirleme\n",
        "data_frequency = pd.infer_freq(data.index)\n",
        "if data_frequency is None:\n",
        "    data_frequency = 'D'\n",
        "\n",
        "# Çoklu Yama Boyutu Projeksiyon Katmanları\n",
        "patch_sizes = {\n",
        "    'D': [7, 14],\n",
        "}\n",
        "\n",
        "selected_patch_sizes = patch_sizes.get(data_frequency, [16,64])\n",
        "print(f\"Seçilen yama boyutları: {selected_patch_sizes}\")\n",
        "\n",
        "def create_time_series_data(data, time_steps=50):\n",
        "    X, y = [], []\n",
        "    for i in range(time_steps, len(data)):\n",
        "        X.append(data[i - time_steps:i, :])\n",
        "        y.append(data[i, :])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Gerçek satış verileri\n",
        "total_sales_2023 = test_data['Net fiyat'].resample('D').sum()\n",
        "\n",
        "# Hata metriklerini kaydetmek için sözlük\n",
        "metrics = {\n",
        "    'r2': [],\n",
        "    'mae': [],\n",
        "    'rmse': [],\n",
        "    'mape': []\n",
        "}\n",
        "\n",
        "# Tüm iterasyon sonuçlarını saklayacak liste\n",
        "all_iterations = []\n",
        "\n",
        "patch_size_results = {size: [] for size in selected_patch_sizes}\n",
        "\n",
        "# HDF5 dosyası varsa yükle, yoksa modeli eğit ve kaydet\n",
        "if os.path.exists(hdf5_filename):\n",
        "    print(\"HDF5 dosyası bulundu, sonuçlar yükleniyor...\")\n",
        "    with h5py.File(hdf5_filename, 'r') as hdf:\n",
        "        for iteration in range(10):\n",
        "            iteration_group = hdf[f'iteration_{iteration + 1}']\n",
        "            predicted_sales = iteration_group['predicted_sales'][:]\n",
        "            real_sales_iteration = iteration_group['real_sales'][:]\n",
        "            errors = iteration_group['errors'][:]\n",
        "\n",
        "            # Hata metriklerini yükle\n",
        "            metrics['r2'].append(iteration_group.attrs['r2'])\n",
        "            metrics['mae'].append(iteration_group.attrs['mae'])\n",
        "            metrics['rmse'].append(iteration_group.attrs['rmse'])\n",
        "            metrics['mape'].append(iteration_group.attrs['mape'])\n",
        "\n",
        "            # İterasyon sonuçlarını yükle\n",
        "            iteration_results = {\n",
        "                'iteration': iteration_group.attrs['iteration'],\n",
        "                'r2': iteration_group.attrs['r2'],\n",
        "                'mae': iteration_group.attrs['mae'],\n",
        "                'rmse': iteration_group.attrs['rmse'],\n",
        "                'mape': iteration_group.attrs['mape'],\n",
        "                'süre (dakika)': iteration_group.attrs['süre (dakika)'],\n",
        "                'süre (saniye)': iteration_group.attrs['süre (saniye)']\n",
        "            }\n",
        "            all_iterations.append(iteration_results)\n",
        "\n",
        "            # LSTM loss history'yi yükle\n",
        "            LSTM_loss_history = iteration_group.attrs.get('LSTM_loss_history', [])\n",
        "\n",
        "            # Patch size sonuçlarını yükle\n",
        "            for patch_size in selected_patch_sizes:\n",
        "                if f'patch_size_{patch_size}' in iteration_group:\n",
        "                    patch_group = iteration_group[f'patch_size_{patch_size}']\n",
        "                    patch_size_results[patch_size].append({\n",
        "                        'iteration': iteration + 1,\n",
        "                        'r2': patch_group.attrs['r2'],\n",
        "                        'mae': patch_group.attrs['mae'],\n",
        "                        'rmse': patch_group.attrs['rmse'],\n",
        "                        'mape': patch_group.attrs['mape']\n",
        "                    })\n",
        "else:\n",
        "    print(\"HDF5 dosyası bulunamadı, model eğitiliyor ve sonuçlar kaydediliyor...\")\n",
        "    with h5py.File(hdf5_filename, 'w') as hdf:\n",
        "        for iteration in range(10):\n",
        "            iteration_start_time = time.time()\n",
        "            print(f\"\\nIteration {iteration + 1}\")\n",
        "\n",
        "            LSTM_loss_history = []\n",
        "\n",
        "            class LSTMLossHistory(tf.keras.callbacks.Callback):\n",
        "                def on_epoch_end(self, epoch, logs={}):\n",
        "                    LSTM_loss_history.append(logs.get('loss'))\n",
        "\n",
        "            # Her patch size için ayrı model oluştur ve eğit\n",
        "            models = []\n",
        "            for patch_size in selected_patch_sizes:\n",
        "                X_train, y_train = create_time_series_data(train_data_scaled, time_steps=patch_size)\n",
        "\n",
        "                model = Sequential([\n",
        "                    Dense(200, activation='relu', input_shape=(patch_size, X_train.shape[2])),  # Mevsimsel Momentum Katmanı kaldırıldı\n",
        "                    LSTM(200, activation='relu', dropout=0.2, recurrent_dropout=0.2),\n",
        "                    Dense(y_train.shape[1])\n",
        "                ])\n",
        "                model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "                model.fit(X_train, y_train, epochs=20, batch_size=64,\n",
        "                          callbacks=[LSTMLossHistory()], verbose=0)\n",
        "                models.append(model)\n",
        "\n",
        "                # Her patch size için ayrı tahmin ve metrik hesaplama\n",
        "                X_test, y_test = create_time_series_data(test_data_scaled, time_steps=patch_size)\n",
        "                pred = model.predict(X_test)\n",
        "\n",
        "                # Tahminleri ters ölçeklendirme\n",
        "                pred_rescaled = scaler.inverse_transform(pred)\n",
        "                y_test_rescaled = scaler.inverse_transform(y_test)\n",
        "\n",
        "                # Performans metriklerini hesapla\n",
        "                r2 = r2_score(y_test_rescaled, pred_rescaled)\n",
        "                mae = mean_absolute_error(y_test_rescaled, pred_rescaled)\n",
        "                rmse = sqrt(mean_squared_error(y_test_rescaled, pred_rescaled))\n",
        "                mape = np.mean(np.abs((y_test_rescaled - pred_rescaled) / (y_test_rescaled + 1e-6))) * 100\n",
        "\n",
        "                patch_size_results[patch_size].append({\n",
        "                    'iteration': iteration + 1,\n",
        "                    'r2': r2,\n",
        "                    'mae': mae,\n",
        "                    'rmse': rmse,\n",
        "                    'mape': mape\n",
        "                })\n",
        "\n",
        "            # En kısa tahmin uzunluğunu bul\n",
        "            predictions = [model.predict(create_time_series_data(test_data_scaled, time_steps=size)[0]) for size, model in zip(selected_patch_sizes, models)]\n",
        "            min_length = min(len(p) for p in predictions)\n",
        "\n",
        "            # Tüm tahminleri en kısa olana göre kırp\n",
        "            predictions = [p[:min_length] for p in predictions]\n",
        "\n",
        "            # Tahminlerin ortalamasını al\n",
        "            LSTM_predicted = np.mean(predictions, axis=0)\n",
        "\n",
        "            # Random Forest Modeli\n",
        "            rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "            rf_model.fit(LSTM_predicted, y_test[:min_length])  # y_test'i de kırp\n",
        "\n",
        "            # Random Forest ile Düzeltilmiş Tahminler\n",
        "            final_predicted = rf_model.predict(LSTM_predicted)\n",
        "            final_predicted = scaler.inverse_transform(final_predicted)\n",
        "\n",
        "            # Tahminleri bir DataFrame'e dönüştür\n",
        "            predicted_df = pd.DataFrame(final_predicted, columns=test_data.columns)\n",
        "            predicted_df.index = test_data.index[:len(predicted_df)]\n",
        "\n",
        "            # Tahmin satış tutarlarını hesapla\n",
        "            predicted_total_sales = predicted_df['Net fiyat'].resample('D').sum()\n",
        "\n",
        "            # Gerçek satış verileri\n",
        "            real_sales_iteration = total_sales_2023.values[:len(predicted_total_sales)]\n",
        "\n",
        "            predicted_sales = predicted_total_sales.values\n",
        "\n",
        "            # Performans metriklerini hesapla\n",
        "            r2 = r2_score(real_sales_iteration, predicted_total_sales)\n",
        "            mae = mean_absolute_error(real_sales_iteration, predicted_total_sales) / (\n",
        "                        np.max(real_sales_iteration) - np.min(real_sales_iteration)) * 100\n",
        "            rmse = sqrt(mean_squared_error(real_sales_iteration, predicted_total_sales)) / (\n",
        "                        np.max(real_sales_iteration) - np.min(real_sales_iteration)) * 100\n",
        "\n",
        "            epsilon = 1e-6\n",
        "            mape = np.mean(\n",
        "                np.abs((real_sales_iteration - predicted_total_sales) / (real_sales_iteration + epsilon))) * 100\n",
        "\n",
        "            print(\"R-kare (R-squared) Değeri:\", r2)\n",
        "            print(\"Ortalama Hata (Mean Absolute Error):\", mae)\n",
        "            print(\"Kök Ortalama Kare Hata (RMSE):\", rmse)\n",
        "            print(\"Ortalama Mutlak Yüzde Hata (MAPE):\", mape)\n",
        "\n",
        "            # Hata metriklerini kaydet\n",
        "            metrics['r2'].append(r2)\n",
        "            metrics['mae'].append(mae)\n",
        "            metrics['rmse'].append(rmse)\n",
        "            metrics['mape'].append(mape)\n",
        "\n",
        "            iteration_end_time = time.time()\n",
        "            iteration_elapsed_time = iteration_end_time - iteration_start_time\n",
        "            minutes = int(iteration_elapsed_time // 60)\n",
        "            seconds = int(iteration_elapsed_time % 60)\n",
        "\n",
        "            # Her iterasyon sonuçlarını kaydet\n",
        "            iteration_results = {\n",
        "                'iteration': iteration + 1,\n",
        "                'r2': r2,\n",
        "                'mae': mae,\n",
        "                'rmse': rmse,\n",
        "                'mape': mape,\n",
        "                'süre (dakika)': minutes,\n",
        "                'süre (saniye)': seconds,\n",
        "            }\n",
        "            all_iterations.append(iteration_results)\n",
        "\n",
        "            # Hataları hesapla\n",
        "            errors = real_sales_iteration - predicted_sales\n",
        "\n",
        "            # İterasyon sonuçlarını HDF5 dosyasına kaydet\n",
        "            iteration_group = hdf.create_group(f'iteration_{iteration + 1}')\n",
        "            iteration_group.create_dataset('predicted_sales', data=predicted_sales)\n",
        "            iteration_group.create_dataset('real_sales', data=real_sales_iteration)\n",
        "            iteration_group.create_dataset('errors', data=errors)\n",
        "            for key, value in iteration_results.items():\n",
        "                iteration_group.attrs[key] = value\n",
        "\n",
        "            # LSTM loss history'yi kaydet\n",
        "            iteration_group.attrs['LSTM_loss_history'] = LSTM_loss_history\n",
        "\n",
        "# 10 çalıştırmanın en iyi, en kötü ve ortalama skorlarını hesapla\n",
        "eniyi_r2 = max(metrics['r2'])\n",
        "eniyi_mae = min(metrics['mae'])\n",
        "eniyi_rmse = min(metrics['rmse'])\n",
        "eniyi_mape = min(metrics['mape'])\n",
        "\n",
        "enkotu_r2 = min(metrics['r2'])\n",
        "enkotu_mae = max(metrics['mae'])\n",
        "enkotu_rmse = max(metrics['rmse'])\n",
        "enkotu_mape = max(metrics['mape'])\n",
        "\n",
        "ortalama_r2 = np.mean(metrics['r2'])\n",
        "ortalama_mae = np.mean(metrics['mae'])\n",
        "ortalama_rmse = np.mean(metrics['rmse'])\n",
        "ortalama_mape = np.mean(metrics['mape'])\n",
        "\n",
        "# En iyi, en kötü ve ortalama sonuçlar için bir DataFrame oluştur (devamı)\n",
        "summary_results = {\n",
        "    'eniyi_r2': [eniyi_r2],\n",
        "    'eniyi_mae': [eniyi_mae],\n",
        "    'eniyi_rmse': [eniyi_rmse],\n",
        "    'eniyi_mape': [eniyi_mape],\n",
        "    'enkotu_r2': [enkotu_r2],\n",
        "    'enkotu_mae': [enkotu_mae],\n",
        "    'enkotu_rmse': [enkotu_rmse],\n",
        "    'enkotu_mape': [enkotu_mape],\n",
        "    'ortalama_r2': [ortalama_r2],\n",
        "    'ortalama_mae': [ortalama_mae],\n",
        "    'ortalama_rmse': [ortalama_rmse],\n",
        "    'ortalama_mape': [ortalama_mape]\n",
        "}\n",
        "summary_df = pd.DataFrame(summary_results)\n",
        "\n",
        "iterations_df = pd.DataFrame(all_iterations)\n",
        "\n",
        "# Excel dosyasına kaydet\n",
        "with pd.ExcelWriter(os.path.join(save_dir, 'seasonal_momentumsuz_LSTM_rf_results.xlsx')) as writer:\n",
        "    iterations_df.to_excel(writer, sheet_name='Iterations', index=False)\n",
        "    summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "# Grafikleri oluştur ve kaydet\n",
        "def save_plt_figure(fig, filename):\n",
        "    filepath = os.path.join(save_dir, filename)\n",
        "    fig.savefig(filepath)\n",
        "    plt.close(fig)\n",
        "\n",
        "# 1. Gerçek vs Tahmin Satışlar Grafiği\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], real_sales_iteration, label='Gerçek Satışlar', color='blue')\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], predicted_sales, label='Tahminler', color='red')\n",
        "plt.title('Gerçek vs Tahmin Satışlar')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Net Fiyat')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '1_gercek_vs_tahmin_satislar_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 2. Performans Metrikleri Karşılaştırma Grafikleri (Ayrı ayrı)\n",
        "metrics_list = ['R-squared', 'MAE', 'RMSE', 'MAPE']\n",
        "metric_values = [r2, mae, rmse, mape]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(len(metrics_list)):\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.bar(metrics_list[i], metric_values[i])\n",
        "    plt.title(metrics_list[i])\n",
        "    plt.ylabel('Değer')\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '2_performans_metrikleri_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 3. Zaman İçinde Hata Değişimi Grafiği\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(total_sales_2023.index[:len(errors)], errors)\n",
        "plt.title('Tahmin Hatalarının Zaman İçindeki Değişimi')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Hata')\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '3_zaman_icinde_hata_degisimi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 4. Eğitim Kaybı Grafiği\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(LSTM_loss_history, label='Eğitim Kaybı')\n",
        "plt.title('Eğitim Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '4_egitim_kaybi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 5. Gerçek ve Tahmin Edilen Değerlerin Karşılaştırılması (Yoğunluk Grafiği)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.kdeplot(real_sales_iteration, fill=True, label='Gerçek')\n",
        "sns.kdeplot(predicted_sales, fill=True, label='Tahmin')\n",
        "plt.title('Gerçek ve Tahmin Edilen Değerlerin Karşılaştırılması')\n",
        "plt.xlabel('Satış Miktarı')\n",
        "plt.ylabel('Yoğunluk')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '5_gercek_vs_tahmin_yogunluk_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 6. Günlük Satış Miktarlarının Zamana Göre Değişimi (Kutu Grafiği)\n",
        "total_sales_df = pd.DataFrame(\n",
        "    {'Tarih': total_sales_2023.index[:len(predicted_sales)], 'Satış Miktarı': real_sales_iteration})\n",
        "total_sales_df['Haftanın Günü'] = total_sales_df['Tarih'].dt.dayofweek\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Haftanın Günü', y='Satış Miktarı', data=total_sales_df)\n",
        "plt.title('Haftanın Günlerine Göre Satış Miktarları')\n",
        "plt.xlabel('Gün')\n",
        "plt.xticks(range(7), ['Pazartesi', 'Salı', 'Çarşamba', 'Perşembe', 'Cuma', 'Cumartesi', 'Pazar'])\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '6_gunluk_satis_miktarlari_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 7. Tahmin Hatalarının Otokorelasyon Fonksiyonu (ACF) ve Kısmi Otokorelasyon Fonksiyonu (PACF)\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig_acf = plot_acf(errors, lags=40)\n",
        "save_plt_figure(fig_acf.figure, '7.1_hata_acf_mevsimsel_momentumsuz.png')\n",
        "\n",
        "fig_pacf = plot_pacf(errors, lags=40)\n",
        "save_plt_figure(fig_pacf.figure, '7.2_hata_pacf_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 8. Mevsimsel Dekompozisyon Grafiği - Bu kısım kaldırıldı\n",
        "\n",
        "# 9. Gerçek vs Tahmin Scatter Plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(real_sales_iteration, predicted_sales)\n",
        "plt.plot([real_sales_iteration.min(), real_sales_iteration.max()],\n",
        "         [real_sales_iteration.min(), real_sales_iteration.max()], 'r--')\n",
        "plt.xlabel('Gerçek Değerler')\n",
        "plt.ylabel('Tahmin Edilen Değerler')\n",
        "plt.title('Gerçek vs Tahmin Scatter Plot')\n",
        "save_plt_figure(plt.gcf(), '9_gercek_vs_tahmin_scatter_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 10. Tahmin Doğruluğu Zaman Çizelgesi\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], np.abs(errors))\n",
        "plt.title('Tahmin Doğruluğu Zaman Çizelgesi')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Mutlak Hata')\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '10_tahmin_dogrulugu_zaman_cizelgesi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 11. Hata Dağılımı Isı Haritası\n",
        "plt.figure(figsize=(12, 8))\n",
        "error_df = pd.DataFrame({'Tarih': total_sales_2023.index[:len(errors)], 'Hata': errors})\n",
        "error_df['Hafta'] = error_df['Tarih'].dt.to_period('W')\n",
        "error_df['Gün'] = error_df['Tarih'].dt.dayofweek\n",
        "pivot = error_df.pivot_table(values='Hata', index='Hafta', columns='Gün', aggfunc='mean')\n",
        "sns.heatmap(pivot, cmap='coolwarm', center=0)\n",
        "plt.title('Hata Dağılımı Isı Haritası')\n",
        "plt.xlabel('Haftanın Günü')\n",
        "plt.ylabel('Hafta')\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '11_hata_dagilimi_isi_haritasi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 12. Kümülatif Satış Karşılaştırması\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], np.cumsum(real_sales_iteration), label='Gerçek Kümülatif Satışlar')\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], np.cumsum(predicted_sales), label='Tahmin Edilen Kümülatif Satışlar')\n",
        "plt.title('Kümülatif Satış Karşılaştırması')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Kümülatif Satış')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '12_kumulatif_satis_karsilastirmasi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 13. Artık Değerlerin Q-Q Grafiği\n",
        "from scipy import stats\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "stats.probplot(errors, dist=\"norm\", plot=plt)\n",
        "plt.title(\"Artık Değerlerin Q-Q Grafiği\")\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '13_artik_degerlerin_qq_grafigi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 14. Tahmin Hatası vs Satış Miktarı Scatter Plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(real_sales_iteration, errors)\n",
        "plt.title('Tahmin Hatası vs Satış Miktarı')\n",
        "plt.xlabel('Gerçek Satış Miktarı')\n",
        "plt.ylabel('Tahmin Hatası')\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '14_tahmin_hatasi_vs_satis_miktari_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 15. Dönemsel Performans Karşılaştırması\n",
        "error_df['Ay'] = error_df['Tarih'].dt.to_period('M')\n",
        "monthly_mae = error_df.groupby('Ay')['Hata'].apply(lambda x: np.mean(np.abs(x)))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "monthly_mae.plot(kind='bar')\n",
        "plt.title('Aylık Ortalama Mutlak Hata (MAE)')\n",
        "plt.xlabel('Ay')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "save_plt_figure(plt.gcf(), '15_aylik_mae_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 16. Haftalık Satışı Görselleştirme - Bu kısım kaldırıldı\n",
        "\n",
        "# 17. Tahmin Doğruluğu Yüzdesi Grafiği\n",
        "plt.figure(figsize=(12, 6))\n",
        "accuracy_percentage = (1 - np.abs(errors) / real_sales_iteration) * 100\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], accuracy_percentage)\n",
        "plt.title('Tahmin Doğruluğu Yüzdesi')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Doğruluk Yüzdesi')\n",
        "plt.ylim(0, 100)\n",
        "save_plt_figure(plt.gcf(), '17_tahmin_dogrulugu_yuzdesi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 18. Residual Lag Plot\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(errors[:-1], errors[1:])\n",
        "plt.title('Residual Lag Plot')\n",
        "plt.xlabel('Hata (t)')\n",
        "plt.ylabel('Hata (t+1)')\n",
        "save_plt_figure(plt.gcf(), '18_residual_lag_plot_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 19. Hata Dağılımının Normallik Testi\n",
        "from scipy import stats\n",
        "_, p_value = stats.shapiro(errors)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(errors, kde=True)\n",
        "plt.title(f'Hata Dağılımı (Shapiro-Wilk p-value: {p_value:.4f})')\n",
        "plt.xlabel('Hata')\n",
        "plt.ylabel('Frekans')\n",
        "save_plt_figure(plt.gcf(), '19_hata_dagilimi_normallik_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 20. Tahmin Sapması Analiz Grafiği\n",
        "bias = np.mean(predicted_sales - real_sales_iteration)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.axhline(y=bias, color='r', linestyle='--')\n",
        "plt.plot(total_sales_2023.index[:len(predicted_sales)], predicted_sales - real_sales_iteration)\n",
        "plt.title(f'Tahmin Sapması (Ortalama Sapma: {bias:.2f})')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Tahmin - Gerçek Değer')\n",
        "save_plt_figure(plt.gcf(), '20_tahmin_sapmasi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "# 21. Yüzdelik Hata Dağılım Grafiği\n",
        "percentage_errors = (errors / real_sales_iteration) * 100\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(percentage_errors, kde=True)\n",
        "plt.title('Yüzdelik Hata Dağılımı')\n",
        "plt.xlabel('Yüzdelik Hata')\n",
        "plt.ylabel('Frekans')\n",
        "save_plt_figure(plt.gcf(), '21_yuzdelik_hata_dagilimi_mevsimsel_momentumsuz.png')\n",
        "\n",
        "print(\"Tüm grafikler başarıyla kaydedildi.\")"
      ]
    }
  ]
}